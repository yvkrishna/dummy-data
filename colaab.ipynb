{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "paddy classifer.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC91dS90hYKH"
      },
      "source": [
        "!git clone https://github.com/yvkrishna/dummy-data.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azTtX3ecNoX8"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os \n",
        "from os import path\n",
        "from PIL import Image, ImageFilter, ImageDraw\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRAzE7xvhbFT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcPYO5Ww2JIY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhaJXmHk2JLG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUHOo_9g2JOC"
      },
      "source": [
        "class Data_Loader:\n",
        "  '''\n",
        "    Class containing methods to load datsets.  \n",
        "  '''\n",
        "  def __init__(self,dataset_dir,data_dir):\n",
        "    '''\n",
        "      Initializes various attributes regarding to the object.\n",
        "      Args :\n",
        "        dataset_dir : (string) the datset containing main folder.\n",
        "        data_dir : (string) the data containing folder with various labels\n",
        "                            as sub folders.\n",
        "    '''\n",
        "    self.dataset_dir = dataset_dir\n",
        "    self.data_dir = data_dir\n",
        "    self.img_label = {}\n",
        "    self.final_data_folder = os.path.join(self.dataset_dir,'processedData')\n",
        "    self.num_classes = 0\n",
        "  \n",
        "  def getClasses(self):\n",
        "    '''\n",
        "      Returns all the class names present in the main directory\n",
        "      Args :\n",
        "        None\n",
        "      Return :\n",
        "        list . A python list containing all classes\n",
        "    '''\n",
        "    data_folder = os.path.join(self.dataset_dir,self.data_dir)\n",
        "    training_classes = [f.name for f in os.scandir(data_folder) if f.is_dir()]\n",
        "    self.num_classes = len(training_classes)\n",
        "    return training_classes\n",
        "\n",
        "\n",
        "  def create_dataset(self,classPath):\n",
        "    '''\n",
        "      moves all the processed images to a single folder and \n",
        "      creates a dictonary with image and its ground truth value.\n",
        "\n",
        "      Args :\n",
        "        classPath : (string) directory containing images for a particular class.\n",
        "\n",
        "      Returns :\n",
        "        dictonary. A python dictonary containing imageName as key\n",
        "                   and one hot encoded class name as value\n",
        "    '''\n",
        "\n",
        "    final_data_folder = os.path.join(self.dataset_dir,'processedData')\n",
        "    \n",
        "\n",
        "    try:\n",
        "      os.mkdir(final_data_folder)    \n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    for image in tqdm(list(os.listdir(classPath))):\n",
        "\n",
        "        if (image.find(\"Images\") == -1):\n",
        "          pass\n",
        "          # path is a image\n",
        "\n",
        "          shutil.move(classPath+\"/\"+image,final_data_folder)\n",
        "\n",
        "          folderName = list(classPath.split(\"/\"))[2]\n",
        "\n",
        "\n",
        "          if (folderName == 'Bacterial leaf blight'):\n",
        "            self.img_label[image] = np.asarray([1,0,0], dtype=np.float32)\n",
        "          elif (folderName == 'Brown spot'):\n",
        "            self.img_label[image] = np.asarray([0,0,1], dtype=np.float32)\n",
        "          else:\n",
        "            self.img_label[image] = np.asarray([0,1,0], dtype=np.float32)\n",
        "\n",
        "\n",
        "        else:\n",
        "          # path is a folder\n",
        "\n",
        "            for image_in_folder in (list(os.listdir(os.path.join(classPath,image)))):\n",
        "              \n",
        "\n",
        "              filtered_image = os.path.join(classPath,image,image_in_folder)\n",
        "              shutil.move(filtered_image,final_data_folder)\n",
        "\n",
        "              folderName = list(classPath.split(\"/\"))[2]\n",
        "\n",
        "\n",
        "              if (folderName == 'Bacterial leaf blight'):\n",
        "                self.img_label[image_in_folder] = np.asarray([1,0,0], dtype=np.float32)\n",
        "              elif (folderName == 'Brown spot'):\n",
        "                self.img_label[image_in_folder] = np.asarray([0,0,1], dtype=np.float32)\n",
        "              else:\n",
        "                self.img_label[image_in_folder] = np.asarray([0,1,0], dtype=np.float32)\n",
        "\n",
        "    return self.img_label\n",
        "\n",
        "  def resize_image(self,img_resize_shape,image_path):\n",
        "    '''\n",
        "      method to resize the image to the given arguments.\n",
        "      Args:\n",
        "        img_resize_shape: (tulpe). The images are\n",
        "                           resized to the given size.\n",
        "        image_path : (string). image name\n",
        "    '''\n",
        "\n",
        "    image_path = os.path.join(self.final_data_folder,image_path)\n",
        "\n",
        "    # Read Image\n",
        "    img = cv2.imread(image_path) \n",
        "\n",
        "    # Resize Image\n",
        "    img = cv2.resize(img, img_resize_shape,  \n",
        "             interpolation = cv2.INTER_NEAREST)\n",
        "    \n",
        "    # return resized image\n",
        "    return img\n",
        "\n",
        "\n",
        "  def prepare_dataset(self,img_resize_shape,train_val_split,img_label_dict):\n",
        "    '''\n",
        "      Resizes the dataset and Prepares train, validation sets.\n",
        "      Args :\n",
        "         img_resize_shape: (tulpe). The images are resized to the given size.\n",
        "\n",
        "         train_val_split: (float). value used to split the entire dataset\n",
        "                                   to train and validation sets.\n",
        "\n",
        "         img_label_dict: (dictonary). contains image name as key and its \n",
        "                                      label as value  \n",
        "\n",
        "    '''\n",
        "\n",
        "    self.img_label = img_label_dict\n",
        "    \n",
        "    # differentiating the complete dataset into training and validating datasets.\n",
        "    img_name_train, img_name_val, output_label_train, output_label_val = train_test_split(\n",
        "                                                                    list(self.img_label.keys()),\n",
        "                                                                    list(self.img_label.values()),\n",
        "                                                                    test_size=train_val_split,\n",
        "                                                                    random_state=0)\n",
        "    \n",
        "\n",
        "\n",
        "    # Creating Numpy Dataset\n",
        "    ( Height, Width ) = img_resize_shape\n",
        "    channels = 3\n",
        "    train_images = np.ndarray(shape=(len(img_name_train), Height, Width, channels), dtype=np.float32)\n",
        "    train_labels = np.ndarray(shape=(len(output_label_train), self.num_classes ), dtype=np.float32)\n",
        "    val_images = np.ndarray(shape=(len(img_name_val), Height, Width, channels), dtype=np.float32)\n",
        "    val_labels = np.ndarray(shape=(len(output_label_val), self.num_classes ), dtype=np.float32)\n",
        "\n",
        "    # Adding Values to the numpy datasets\n",
        "    i=0\n",
        "    for image in list(img_name_train):\n",
        "      x = self.resize_image(img_resize_shape,image)\n",
        "      train_images[i] = x\n",
        "      train_labels[i] = np.asarray(output_label_train[i])\n",
        "      i += 1\n",
        "\n",
        "\n",
        "    i=0\n",
        "    for image in list(img_name_val):\n",
        "      x = self.resize_image(img_resize_shape,image)\n",
        "      val_images[i] = x\n",
        "      val_labels[i] = np.asarray(output_label_val[i])\n",
        "      i += 1\n",
        "\n",
        "      return (train_images,train_labels,val_images,val_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itxHeAOd6SaY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTMtLpXA6Sc3"
      },
      "source": [
        "class Filters:\n",
        "  '''\n",
        "    Class containing methods to apply filters to images in the data folder  \n",
        "  '''\n",
        "\n",
        "  def __init__(self,filters):\n",
        "    '''\n",
        "      Initializes various attributes regarding to the object.\n",
        "      Args : \n",
        "        filters : (List) python list containing various filters to \n",
        "                         be applied to the image data.\n",
        "    '''\n",
        "    self.filters = filters\n",
        "\n",
        "\n",
        "  def applyMedian(self,classPath):\n",
        "    ''' \n",
        "      Applies Median Filter to all the images in the given folder. \n",
        "      Args : \n",
        "        classPath : (string) directory containing images for a particular class.\n",
        "    '''\n",
        "    try:\n",
        "      os.mkdir(classPath+\"/MedianImages\")    \n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    for image in tqdm(list(os.listdir(classPath))):\n",
        "      # Read image\n",
        "      img = cv2.imread(classPath+\"/\"+image)\n",
        "\n",
        "      if img is not None:\n",
        "        # applies median filter to the image.\n",
        "        median = cv2.medianBlur(img, 5)\n",
        "        \n",
        "        # saving the image by\n",
        "        plt.imsave(classPath+\"/MedianImages/Median\"+image, median)\n",
        "  \n",
        "  def applylaplacian(self,classPath):\n",
        "    ''' \n",
        "      Applies Laplacian Filter to all the images in the given folder. \n",
        "      Args : \n",
        "        classPath : (string) directory containing images for a particular class.\n",
        "    '''\n",
        "    \n",
        "    try:\n",
        "      os.mkdir(classPath+\"/LaplacianImages\")    \n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    for image in tqdm(list(os.listdir(classPath))):\n",
        "      # Read image\n",
        "      img = cv2.imread(classPath+\"/\"+image)\n",
        "\n",
        "      if img is not None:\n",
        "        # applying laplacian filter\n",
        "        laplacian = cv2.Laplacian(img,cv2.CV_64F)\n",
        "        \n",
        "        # saving the image.\n",
        "        cv2.imwrite(classPath+\"/LaplacianImages/laplacian\"+image, laplacian)\n",
        "\n",
        "  def applysobelx(self,classPath):\n",
        "    ''' \n",
        "      Applies Sobel-x Filter to all the images in the given folder. \n",
        "      Args : \n",
        "        classPath : (string) directory containing images for a particular class.\n",
        "    '''\n",
        "\n",
        "    try:\n",
        "      os.mkdir(classPath+\"/SobelxImages\")    \n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    for image in tqdm(list(os.listdir(classPath))):\n",
        "      # Read image\n",
        "      img = cv2.imread(classPath+\"/\"+image)\n",
        "\n",
        "      if img is not None:\n",
        "        # applying sobelx filter\n",
        "        sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\n",
        "        \n",
        "        # saving the image.\n",
        "        cv2.imwrite(classPath+\"/SobelxImages/sobelx\"+image, sobelx)\n",
        "\n",
        "  def applysobely(self,classPath):\n",
        "    ''' \n",
        "      Applies Sobel-y Filter to all the images in the given folder. \n",
        "      Args : \n",
        "        classPath : (string) directory containing images for a particular class.\n",
        "    '''\n",
        "    try:\n",
        "      os.mkdir(classPath+\"/SobelyImages\")    \n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    for image in tqdm(list(os.listdir(classPath))):\n",
        "      # Read image\n",
        "      img = cv2.imread(classPath+\"/\"+image)\n",
        "\n",
        "      if img is not None:\n",
        "        # applying Sobel-y filter\n",
        "        sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)\n",
        "        \n",
        "        # saving the image.\n",
        "        cv2.imwrite(classPath+\"/SobelyImages/sobely\"+image, sobely)\n",
        "\n",
        "\n",
        "  def applygaussian(self,classPath):\n",
        "    ''' \n",
        "      Applies gaussian Filter to all the images in the given folder. \n",
        "      Args : \n",
        "        classPath : (string) directory containing images for a particular class.\n",
        "    '''\n",
        "\n",
        "    try:\n",
        "      os.mkdir(classPath+\"/GaussianImages\")    \n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    for image in tqdm(list(os.listdir(classPath))):\n",
        "      # Read image\n",
        "      img = cv2.imread(classPath+\"/\"+image)\n",
        "\n",
        "      if img is not None:\n",
        "        # applying gaussian filter\n",
        "        gaussian = cv2.GaussianBlur(img,(5,5),0)\n",
        "        \n",
        "        # saving the image.\n",
        "        plt.imsave(classPath+\"/GaussianImages/gaussian\"+image, gaussian)\n",
        "\n",
        "  def visualizeFilters(self):\n",
        "    ''' filtered_image\n",
        "      visualizes various filtered outputs \n",
        "    '''\n",
        "\n",
        "    ####### Note #######\n",
        "    ''' To be completed '''\n",
        "    ####### Note #######\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwMon_wsAPeC"
      },
      "source": [
        "class Data_Augumentation:\n",
        "  '''\n",
        "    Class containing methods to apply Data Augumentation techniques\n",
        "    to images in the data folder  \n",
        "  '''\n",
        "\n",
        "  def __init__(self,techniques):\n",
        "    '''\n",
        "      Initializes various attributes regarding to the object.\n",
        "      Args : \n",
        "        techniques : (dictonary) python dictonary containing key value pairs\n",
        "                      of techniques and values to be applied to the image data.\n",
        "    '''\n",
        "    self.techniques = techniques\n",
        "\n",
        "  ####### Note #######\n",
        "  ''' To be completed '''\n",
        "  ####### Note #######"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTVydHgrAPg5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6kYnNieQ54A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfLdSUB7MHi3"
      },
      "source": [
        "l1 = Data_Loader('dummy-data','rice_leaf_diseases')\n",
        "training_classes = l1.getClasses()\n",
        "\n",
        "filters = [\"median\",\"laplacian\",\"sobelx\",\"sobely\",\"gaussian\"]\n",
        "f1 = Filters(filters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzAUF0ZbMHmA"
      },
      "source": [
        "for folder in training_classes:\n",
        "  for filter in filters:\n",
        "    path = os.path.join('dummy-data','rice_leaf_diseases', folder)\n",
        "    if filter == \"median\":\n",
        "      f1.applyMedian(path)\n",
        "    elif filter == \"laplacian\":\n",
        "      f1.applylaplacian(path)\n",
        "    elif filter == \"sobelx\":\n",
        "      f1.applysobelx(path)\n",
        "    elif filter == \"sobely\":\n",
        "      f1.applysobely(path)\n",
        "    elif filter == \"gaussian\":\n",
        "      f1.applygaussian(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrYaj21jMHrl"
      },
      "source": [
        "for folder in training_classes:\n",
        "  path = os.path.join('dummy-data','rice_leaf_diseases', folder)\n",
        "  img_label = l1.create_dataset(path)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuEYIJ_OJR77"
      },
      "source": [
        "(train_x, train_y, val_x, val_y) = l1.prepare_dataset((150,150),0.1,img_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N4AK428JR-7"
      },
      "source": [
        "print(train_x.shape,train_y.shape,val_x.shape, val_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFOlqCJBJSDG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaQchRuUJSGb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vduiaZIyDR50"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Zxey9SoDR88"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdskoZvgDSBW"
      },
      "source": [
        "newpath = os.path.join('dummy-data','processedData')\n",
        "print(newpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy90wbxwDSEt"
      },
      "source": [
        "for image in (list(os.listdir(newpath))):\n",
        "  img = cv2.imread(newpath+\"/\"+image)\n",
        "  if (img.shape[2] != 3):\n",
        "    print(newpath+\"/\"+image)\n",
        "    break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWF7HaOOD48r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0olIIG3D4_n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR77-NqA6Sl5"
      },
      "source": [
        "imageFolder = os.path.join('dummy-data','rice_leaf_diseases', 'Bacterial leaf blight')\n",
        "numfiles = len(list(os.listdir(imageFolder)))\n",
        "print(\"{} contains {} images\".format(imageFolder,str(numfiles)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwJx63ZX6Soe"
      },
      "source": [
        "final_data_folder = os.path.join('dummy-data','processedData')\n",
        "print(final_data_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DXq0uK86SrA"
      },
      "source": [
        "imageFolder = os.path.join('dummy-data','rice_leaf_diseases', 'Bacterial leaf blight',\"MedianImages\",\"abcdef.png\")\n",
        "print(list(image.split(\"/\"))[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRSttBax2JVt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU1-JYKBPAER"
      },
      "source": [
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHO7qXc-nVeM"
      },
      "source": [
        "os.chdir('paddy_disease_classification/rice_leaf_diseases')\n",
        "path = os.getcwd()\n",
        "training_classes = [f.name for f in os.scandir(path) if f.is_dir()]\n",
        "print(training_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtdvFjYHCORP"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXHis6zDo1EY"
      },
      "source": [
        "def applyMedian(folder):\n",
        "  ''' \n",
        "    Applies Meadian Filter to all the images in the given folder. \n",
        "    Args : \n",
        "      Folder : (str). : Image_directory\n",
        "  '''\n",
        "  previous_path = os.getcwd()\n",
        "  os.chdir(folder)\n",
        "  current_path = os.getcwd()\n",
        "\n",
        "  for image in tqdm(list(os.listdir(current_path))):\n",
        "    img = cv2.imread(image)\n",
        "    # applies median filter to the image.\n",
        "    median = cv2.medianBlur(img, 5)\n",
        "    # saving the image by adding the blur feature.\n",
        "    im = Image.fromarray(median)\n",
        "    im.save(image)\n",
        "  os.chdir(previous_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYJQMPRM0hqw"
      },
      "source": [
        "  for folder in training_classes:\n",
        "    applyMedian(folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqoubpPR467k"
      },
      "source": [
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRucI3QqVrVy"
      },
      "source": [
        "base_dir = 'paddy_disease_classification'\n",
        "train_dir = os.path.join(base_dir, 'rice_leaf_diseases')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkpRx2aY47C2"
      },
      "source": [
        "train_bact_leaf_smut_dir = os.path.join(train_dir, 'Bacterial leaf blight')  # directory with our training cat pictures\n",
        "train_brown_spot_dir = os.path.join(train_dir, 'Brown spot')  # directory with our training dog pictures\n",
        "train_leaf_smut_dir = os.path.join(train_dir, 'Leaf smut')  # directory with our training dog pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBc67CSp5nPg"
      },
      "source": [
        "num_bact_leaf_smut_tr = len(os.listdir(train_bact_leaf_smut_dir))\n",
        "num_brown_spot_tr = len(os.listdir(train_brown_spot_dir))\n",
        "num_leaf_smut_tr = len(os.listdir(train_leaf_smut_dir))\n",
        "\n",
        "total_train = num_bact_leaf_smut_tr + num_brown_spot_tr + num_leaf_smut_tr\\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-22gZwup6Nt-"
      },
      "source": [
        "print('Data before Data augumentation')\n",
        "print(\"--\")\n",
        "print('total training Bacterial leaf blight images:', num_bact_leaf_smut_tr)\n",
        "print('total training Brown spot images:', num_brown_spot_tr)\n",
        "print('total training Leaf smut images:', num_leaf_smut_tr)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI3gETR08FP8"
      },
      "source": [
        "BATCH_SIZE = 20\n",
        "IMG_SHAPE  = 299"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f2dvgsoC5nj"
      },
      "source": [
        "def rotateImages(rotationAmt,folder):\n",
        "  '''\n",
        "    rotateImages is used as one of the image augumentation techniques to \n",
        "    increase the dataset thereby increasing the accuracy.\n",
        "\n",
        "    rotateImages function rotates images in the current directory.\n",
        "\n",
        "   Args:\n",
        "   rotationAmt : int. The value of rotation in the image.\n",
        "   \n",
        "  '''\n",
        "  previous_path = os.getcwd()\n",
        "  os.chdir(folder)\n",
        "  current_path = os.getcwd()\n",
        "\n",
        "  total_images = 0\n",
        "\n",
        "  for image in tqdm(list(os.listdir(current_path))):\n",
        "    # check if the image is already rotated. \n",
        "    if (image.find(\"rot\") == -1): \n",
        "      img = Image.open(image)\n",
        "      # get the image name\n",
        "      img_name = list(image.split(\".\"))[0]\n",
        "      rotimg = img.rotate(rotationAmt)\n",
        "      # saving the image with its rotation information as well.\n",
        "      rotimg.save(img_name+\"rot\"+str(rotationAmt)+\".jpg\")\n",
        "      img.close()\n",
        "      total_images+=1\n",
        "  print(total_images)\n",
        "  os.chdir(previous_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZUcOdUkC5k7"
      },
      "source": [
        "def addBlur(folder):\n",
        "  '''\n",
        "    Adds Blur to the images.\n",
        "    This function will list out all the images in the current directory and \n",
        "    applies blur to the image and saves it in the same folder.\n",
        "  '''\n",
        "  previous_path = os.getcwd()\n",
        "  os.chdir(folder)\n",
        "  current_path = os.getcwd()\n",
        "  # for each image in the current directory\n",
        "  total_images = 0\n",
        "\n",
        "  for image in tqdm(list(os.listdir(current_path))):\n",
        "    if (image.find(\"rot\") == -1): \n",
        "      img = Image.open(image)\n",
        "      # adds blur to the image using ImageFilter.Blur\n",
        "      blured_image = img.filter(ImageFilter.BLUR)\n",
        "      # get the image name\n",
        "      img_name = list(image.split(\".\"))[0]\n",
        "      # saving the image by adding the blur feature.\n",
        "      blured_image.save(img_name+\"blur.jpg\")\n",
        "      total_images+=1\n",
        "  print(total_images)\n",
        "  os.chdir(previous_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt58a9g4C5fm"
      },
      "source": [
        "def horizontalFlip(folder):\n",
        "  '''\n",
        "    Adds Blur to the images.\n",
        "    This function will list out all the images in the current directory and \n",
        "    applies blur to the image and saves it in the same folder.\n",
        "  '''\n",
        "  previous_path = os.getcwd()\n",
        "  os.chdir(folder)\n",
        "  current_path = os.getcwd()\n",
        "  # for each image in the current directory\n",
        "  total_images = 0\n",
        "\n",
        "  for image in tqdm(list(os.listdir(current_path))):\n",
        "    if (image.find(\"rot\") == -1 and image.find(\"blur\") == -1): \n",
        "      img = cv2.imread(image) \n",
        "      # Flips the image\n",
        "      flip = cv2.flip(img, 1)\n",
        "      # get the image name\n",
        "      img_name = list(image.split(\".\"))[0]\n",
        "      # saving the image by adding the flip feature.\n",
        "      cv2.imwrite(img_name+\"flip.jpg\",flip)\n",
        "      total_images+=1\n",
        "  print(total_images)\n",
        "  os.chdir(previous_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeSOsjGoGCuH"
      },
      "source": [
        "os.chdir('paddy_disease_classification/testing')\n",
        "for folder in training_classes:\n",
        "  # Rotating images of train_label_img_locations with an angle of 90 deg.\n",
        "  rotateImages(90,folder)\n",
        "\n",
        "  # Blur images in train_label_img_locations\n",
        "  addBlur(folder)\n",
        "\n",
        "  # # Adds Uniform Noise to images in train_label_img_locations\n",
        "  # addUniformNoise(folder)\n",
        "\n",
        "  # horizontally flips the images\n",
        "  horizontalFlip(folder)\n",
        "\n",
        "  print()\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2A1lUpv2fwY"
      },
      "source": [
        "os.chdir('paddy_disease_classification/rice_leaf_diseases')\n",
        "for folder in training_classes:\n",
        "  # Rotating images of train_label_img_locations with an angle of 90 deg.\n",
        "  rotateImages(90,folder)\n",
        "\n",
        "  # Blur images in train_label_img_locations\n",
        "  addBlur(folder)    previous_path = os.getcwd()\n",
        "    os.chdir(folder)\n",
        "    current_path = os.getcwd()\n",
        "\n",
        "  # # Adds Uniform Noise to images in train_label_img_locations\n",
        "  # addUniformNoise(folder)\n",
        "\n",
        "  # horizontally flips the images\n",
        "  horizontalFlip(folder)\n",
        "\n",
        "  print()\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6wx_kdyLsv_"
      },
      "source": [
        "base_dir = 'paddy_disease_classification'\n",
        "train_dir = os.path.join(base_dir, 'rice_leaf_diseases')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpiY2M5qLswD"
      },
      "source": [
        "train_bact_leaf_smut_dir = os.path.join(train_dir, 'Bacterial leaf blight')  # directory with our training cat pictures\n",
        "train_brown_spot_dir = os.path.join(train_dir, 'Brown spot')  # directory with our training dog pictures\n",
        "train_leaf_smut_dir = os.path.join(train_dir, 'Leaf smut')  # directory with our training dog pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ifsw_YPLswG"
      },
      "source": [
        "num_bact_leaf_smut_tr = len(os.listdir(train_bact_leaf_smut_dir))\n",
        "num_brown_spot_tr = len(os.listdir(train_brown_spot_dir))\n",
        "num_leaf_smut_tr = len(os.listdir(train_leaf_smut_dir))\n",
        "\n",
        "total_train = num_bact_leaf_smut_tr + num_brown_spot_tr + num_leaf_smut_tr\\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlhcO3HwLswJ"
      },
      "source": [
        "print('Data after Data augumentation')\n",
        "print(\"--\")\n",
        "print('total training Bacterial leaf blight images:', num_bact_leaf_smut_tr)\n",
        "print('total training Brown spot images:', num_brown_spot_tr)\n",
        "print('total training Leaf smut images:', num_leaf_smut_tr)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HzxZiSMPA8l"
      },
      "source": [
        "os.chdir('paddy_disease_classification')\n",
        "!mkdir train\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Lclwc3hNPVL"
      },
      "source": [
        "def create_dataset(folder):\n",
        "  previous_path = os.getcwd()\n",
        "  os.chdir(folder)\n",
        "  current_path = os.getcwd()\n",
        "  # for each image in the current directory\n",
        "  total_images = 0\n",
        "\n",
        "  for image in tqdm(list(os.listdir(current_path))):\n",
        "\n",
        "    shutil.move(image, \"/content/paddy_disease_classification/train\")\n",
        "\n",
        "    if (folder=='Bacterial leaf blight'):\n",
        "      img_label[image] = np.asarray([1,0,0], dtype=np.float32)\n",
        "    elif (folder=='Brown spot'):\n",
        "      img_label[image] = np.asarray([0,0,1], dtype=np.float32)\n",
        "    else:\n",
        "      img_label[image] = np.asarray([0,1,0], dtype=np.float32)\n",
        " \n",
        "  os.chdir(previous_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U54lUP6NPZ9"
      },
      "source": [
        "os.chdir('paddy_disease_classification/rice_leaf_diseases')\n",
        "\n",
        "img_label = {}\n",
        "\n",
        "for folder in training_classes:\n",
        "  create_dataset(folder)\n",
        "  \n",
        "\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-YSjS7HNPSr"
      },
      "source": [
        "print(img_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kPsNzqHQ_gU"
      },
      "source": [
        "\n",
        "def load_image(image_path):\n",
        "    '''\n",
        "      Converts the image to size = (299,299,3) and normalizes the data\n",
        "      Args : \n",
        "      image_path : str. Image path for processing the image\n",
        "    '''\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, (299, 299))\n",
        "    # Normalizing the image\n",
        "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "    return img, image_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5_TOSCDQ_dy"
      },
      "source": [
        "# Test code for checking the image shape and max value of image\n",
        "os.chdir('paddy_disease_classification/train')\n",
        "image, path = load_image('DSC_0112blur.jpg')\n",
        "print(f\"image has a shape of {image.shape}\")\n",
        "print(tf.reduce_max(image))\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUKSdu0hRNw_"
      },
      "source": [
        "# differentiating the complete dataset into training and validating datasets.\n",
        "img_name_train, img_name_val, output_label_train, output_label_val = train_test_split(\n",
        "                                                                    list(img_label.keys()),\n",
        "                                                                    list(img_label.values()),\n",
        "                                                                    test_size=0.1,\n",
        "                                                                    random_state=0)\n",
        "\n",
        "print(f'Length of training images = {len(img_name_train)}')\n",
        "print(f'Length of training labels = {len(output_label_train)}')\n",
        "print(f\"Length of validating images = {len(img_name_val)}\")\n",
        "print(f'Length of validating labels = {len(output_label_val)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--oB771ZRNup"
      },
      "source": [
        "os.chdir('paddy_disease_classification/train')\n",
        "\n",
        "channels = 3\n",
        "\n",
        "train_images = np.ndarray(shape=(len(img_name_train), IMG_SHAPE, IMG_SHAPE, channels), dtype=np.float32)\n",
        "train_labels = np.ndarray(shape=(len(output_label_train), 3 ), dtype=np.float32)\n",
        "val_images = np.ndarray(shape=(len(img_name_val), IMG_SHAPE, IMG_SHAPE, channels), dtype=np.float32)\n",
        "val_labels = np.ndarray(shape=(len(output_label_val), 3 ), dtype=np.float32)\n",
        "\n",
        "i=0\n",
        "for image in tqdm(list(img_name_train)):\n",
        "  x, path = load_image(image)\n",
        "  train_images[i] = x\n",
        "  train_labels[i] = np.asarray(output_label_train[i])\n",
        "  i += 1\n",
        "\n",
        "\n",
        "i=0\n",
        "for image in tqdm(list(img_name_val)):\n",
        "  x, path = load_image(image)\n",
        "  val_images[i] = x\n",
        "  val_labels[i] = np.asarray(output_label_val[i])\n",
        "  i += 1\n",
        "\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m17crgDUnGjl"
      },
      "source": [
        "train_images.shape, train_labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-dKNHfkfyHP"
      },
      "source": [
        "os.chdir('paddy_disease_classification')\n",
        "!mkdir train\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haTgBsMefyHj"
      },
      "source": [
        "def create_dataset(folder):\n",
        "  previous_path = os.getcwd()\n",
        "  os.chdir(folder)\n",
        "  current_path = os.getcwd()\n",
        "  # for each image in the current directory\n",
        "  total_images = 0\n",
        "\n",
        "  for image in tqdm(list(os.listdir(current_path))):\n",
        "\n",
        "    shutil.move(image, \"/content/paddy_disease_classification/train\")\n",
        "\n",
        "    if (folder=='Bacterial leaf blight'):\n",
        "      img_label[image] = np.asarray([1,0,0], dtype=np.float32)\n",
        "    elif (folder=='Brown spot'):\n",
        "      img_label[image] = np.asarray([0,0,1], dtype=np.float32)\n",
        "    else:\n",
        "      img_label[image] = np.asarray([0,1,0], dtype=np.float32)\n",
        " \n",
        "  os.chdir(previous_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhPhjdKQfyHt"
      },
      "source": [
        "os.chdir('paddy_disease_classification/rice_leaf_diseases')\n",
        "\n",
        "img_label = {}\n",
        "\n",
        "for folder in training_classes:\n",
        "  create_dataset(folder)\n",
        "  \n",
        "\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3BVAZ0MfyH5"
      },
      "source": [
        "print(img_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwzW4v8wfyIB"
      },
      "source": [
        "\n",
        "def load_image(image_path):\n",
        "    '''\n",
        "      Converts the image to size = (299,299,3) and normalizes the data\n",
        "      Args : \n",
        "      image_path : str. Image path for processing the image\n",
        "    '''\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, (299, 299))\n",
        "    # Normalizing the image\n",
        "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "    return img, image_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX6c8d20fyIH"
      },
      "source": [
        "# Test code for checking the image shape and max value of image\n",
        "os.chdir('paddy_disease_classification/train')\n",
        "image, path = load_image('DSC_0112blur.jpg')\n",
        "print(f\"image has a shape of {image.shape}\")\n",
        "print(tf.reduce_max(image))\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnyEzvGofyIO"
      },
      "source": [
        "# differentiating the complete dataset into training and validating datasets.\n",
        "img_name_train, img_name_val, output_label_train, output_label_val = train_test_split(\n",
        "                                                                    list(img_label.keys()),\n",
        "                                                                    list(img_label.values()),\n",
        "                                                                    test_size=0.1)\n",
        "\n",
        "print(f'Length of training images = {len(img_name_train)}')\n",
        "print(f'Length of training labels = {len(output_label_train)}')\n",
        "print(f\"Length of validating images = {len(img_name_val)}\")\n",
        "print(f'Length of validating labels = {len(output_label_val)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJEgzTZhfyIU"
      },
      "source": [
        "os.chdir('paddy_disease_classification/train')\n",
        "\n",
        "channels = 3\n",
        "\n",
        "train_images = np.ndarray(shape=(len(img_name_train), IMG_SHAPE, IMG_SHAPE, channels), dtype=np.float32)\n",
        "train_labels = np.ndarray(shape=(len(output_label_train), 3 ), dtype=np.float32)\n",
        "val_images = np.ndarray(shape=(len(img_name_val), IMG_SHAPE, IMG_SHAPE, channels), dtype=np.float32)\n",
        "val_labels = np.ndarray(shape=(len(output_label_val), 3 ), dtype=np.float32)\n",
        "\n",
        "i=0\n",
        "for image in tqdm(list(img_name_train)):\n",
        "  x, path = load_image(image)\n",
        "  train_images[i] = x\n",
        "  train_labels[i] = np.asarray(output_label_train[i])\n",
        "  i += 1\n",
        "\n",
        "\n",
        "i=0\n",
        "for image in tqdm(list(img_name_val)):\n",
        "  x, path = load_image(image)\n",
        "  val_images[i] = x\n",
        "  val_labels[i] = np.asarray(output_label_val[i])\n",
        "  i += 1\n",
        "\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBvJId4yfyIZ"
      },
      "source": [
        "train_images.shape, train_labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F82PmT3Wh3tK"
      },
      "source": [
        "# Pre trained model \n",
        "inception_V3_pre_trained = InceptionV3(include_top=True, weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnFJvw3Fh3ye"
      },
      "source": [
        "for layer in inception_V3_pre_trained.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "predictions = Dense(3, activation='softmax')(inception_V3_pre_trained.output)\n",
        "inception_V3 = Model(inputs=inception_V3_pre_trained.input, outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6gEe3Qph31W"
      },
      "source": [
        "adam = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.00001, beta_1=0.9, beta_2=0.9999, epsilon=1e-08,\n",
        "    amsgrad=True, name='Adam' )\n",
        "\n",
        "inception_V3.compile(\n",
        "  optimizer=adam,\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy',tf.keras.metrics.AUC()])\n",
        "\n",
        "EPOCHS = 20\n",
        "history_inception_V3 = inception_V3.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=10,\n",
        "    validation_data=(val_images, val_labels)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItUxJVWZiEax"
      },
      "source": [
        "acc = history_inception_V3.history['accuracy']\n",
        "val_acc = history_inception_V3.history['val_accuracy']\n",
        "\n",
        "loss = history_inception_V3.history['loss']\n",
        "val_loss = history_inception_V3.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "plt.figure(num=None, figsize=(20,20), dpi=40, facecolor='w', edgecolor='k')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label = 'validation Accuracy')\n",
        "plt.legend(loc='lower right',fontsize=20)\n",
        "plt.title('Accuracy Plot',fontsize=30)\n",
        "plt.xlabel('Number of Epochs',fontsize=30)\n",
        "plt.ylabel('Accuracy',fontsize=30)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label = 'validation Loss')\n",
        "plt.legend(loc='upper right',fontsize=20)\n",
        "plt.title('Loss Plot',fontsize=30)\n",
        "plt.xlabel('Number of Epochs',fontsize=30)\n",
        "plt.ylabel('Loss',fontsize=30)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZZLYmQiNeLx"
      },
      "source": [
        "def Get_Results_Inception_V3(folder):\n",
        "  ''' \n",
        "    Generates results for Inception_Resnet_V2 model\n",
        "      Folder : (str). : Image_directory\n",
        "  '''\n",
        "  previous_path = os.getcwd()\n",
        "  os.chdir(folder)\n",
        "  current_path = os.getcwd()\n",
        "  predicts = []\n",
        "\n",
        "  for image in tqdm(list(os.listdir(current_path))):\n",
        "    # img = cv2.imread(image)\n",
        "    # median = cv2.medianBlur(img, 5)\n",
        "    # im = Image.fromarray(median)\n",
        "    # im.save(image)\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image, target_size=(299,299, 3))\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "\n",
        "    result_inception_v3['image_names'].append(image)\n",
        "    predicts.append(inception_V3.predict(img)[0])\n",
        "\n",
        "    if (folder=='Bacterial leaf blight'):\n",
        "      result_inception_v3['ground_truths'].append(np.asarray([1,0,0]))\n",
        "    elif (folder=='Brown spot'):\n",
        "      result_inception_v3['ground_truths'].append(np.asarray([0,0,1]))\n",
        "    else:\n",
        "      result_inception_v3['ground_truths'].append(np.asarray([0,1,0]))\n",
        "  \n",
        "  result_inception_v3['predictions'].append(predicts)\n",
        "  os.chdir(previous_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJBZNTYdNSRD"
      },
      "source": [
        "result_inception_v3 = {'predictions':[],'image_names':[],'ground_truths':[]}\n",
        "os.chdir('paddy_disease_classification/testing')\n",
        "\n",
        "for folder in training_classes:\n",
        "  Get_Results_Inception_V3(folder)\n",
        "\n",
        "os.chdir('/content')\n",
        "result_inception_v3['predictions'] = np.asarray(result_inception_v3['predictions']).reshape((60, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erem_7veNSRi"
      },
      "source": [
        "print(np.asarray(result_inception_v3['ground_truths']))\n",
        "print(np.asarray(result_inception_v3['predictions']))\n",
        "print(np.asarray(result_inception_v3['ground_truths']).shape)\n",
        "print(np.asarray(result_inception_v3['predictions']).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9TFl5C4NSRn"
      },
      "source": [
        "pred = np.asarray(result_inception_v3['predictions'])\n",
        "pred = np.argmax(pred, axis=1).reshape(-1)\n",
        "pred = np.asarray(np.eye(len(training_classes),dtype=int)[pred])\n",
        "print(pred)\n",
        "print(pred.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoTGHXXUNSRr"
      },
      "source": [
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(len(training_classes)):\n",
        "    fpr[i], tpr[i], _ = roc_curve(result_inception_v3['ground_truths'][i], result_inception_v3['predictions'][i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(np.asarray(result_inception_v3['ground_truths']).ravel(),np.asarray(result_inception_v3['predictions']).ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LobYmmQNSRv"
      },
      "source": [
        "# First aggregate all false positive rates\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(len(training_classes))]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(len(training_classes)):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= len(training_classes)\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves\n",
        "lw = 2\n",
        "plt.figure()\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "         label='macro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "for i, color in zip(range(len(training_classes)), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic using Inception-V3')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_CSzTjFNSRz"
      },
      "source": [
        "data = {'y_Actual': [np.where(r==1)[0][0] for r in np.asarray(result_inception_v3['ground_truths'])],\n",
        "        'y_Predicted': [np.where(r==1)[0][0] for r in pred]\n",
        "        }\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
        "\n",
        "sn.heatmap(confusion_matrix, annot=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}